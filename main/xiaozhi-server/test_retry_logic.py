#!/usr/bin/env python3
"""
Test script to verify LLM retry logic
This will test both successful connections and retry scenarios
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.providers.llm.openai.openai import LLMProvider
from config.logger import setup_logging
import time

# Setup logging
logger = setup_logging()

def test_successful_connection():
    """Test normal operation with valid API key"""
    print("\n[TEST 1] Normal operation with valid Groq API key")
    print("="*60)
    
    config = {
        "type": "openai",
        "api_key": "your-groq-api-key-here",
        "base_url": "https://api.groq.com/openai/v1",
        "model_name": "openai/gpt-oss-20b",
        "temperature": 0.7,
        "max_tokens": 50,  # Small for quick test
        "timeout": 15,
        "max_retries": 2,
        "retry_delay": 1
    }
    
    try:
        llm = LLMProvider(config)
        
        dialogue = [
            {"role": "user", "content": "Say 'Hello from Cheeko!' in exactly those words."}
        ]
        
        print("üì§ Sending request to Groq...")
        start_time = time.time()
        
        response_text = ""
        for chunk in llm.response("test_session", dialogue):
            if chunk and not chunk.startswith("[OpenAI Service Response Exception"):
                response_text += chunk
                print(f"üì• Received: {chunk}", end="", flush=True)
        
        end_time = time.time()
        
        print(f"\n‚úÖ Success! Response time: {end_time - start_time:.2f}s")
        print(f"üìù Full response: {response_text.strip()}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False

def test_invalid_api_key():
    """Test retry logic with invalid API key (should trigger 401 errors)"""
    print("\nüß™ TEST 2: Testing retry logic with invalid API key")
    print("="*60)
    
    config = {
        "type": "openai",
        "api_key": "invalid_key_to_trigger_401_error",  # Invalid key
        "base_url": "https://api.groq.com/openai/v1",
        "model_name": "openai/gpt-oss-20b",
        "temperature": 0.7,
        "max_tokens": 50,
        "timeout": 15,
        "max_retries": 2,  # Should try twice
        "retry_delay": 1   # 1 second between attempts
    }
    
    try:
        llm = LLMProvider(config)
        
        dialogue = [
            {"role": "user", "content": "Hello"}
        ]
        
        print("üì§ Sending request with invalid API key...")
        print("‚è≥ Should see 2 retry attempts with 1s delay between them...")
        
        start_time = time.time()
        
        response_text = ""
        for chunk in llm.response("test_session", dialogue):
            response_text += chunk
            if chunk.startswith("[OpenAI Service Response Exception"):
                print(f"üì• {chunk}")
            else:
                print(f"üì• Received: {chunk}")
        
        end_time = time.time()
        
        print(f"\n‚ö†Ô∏è  Expected failure completed in {end_time - start_time:.2f}s")
        print("‚úÖ Retry logic working - should have taken ~2+ seconds due to retry delay")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed unexpectedly: {e}")
        return False

def test_timeout_scenario():
    """Test with very short timeout to trigger timeout retry"""
    print("\nüß™ TEST 3: Testing timeout scenario")
    print("="*60)
    
    config = {
        "type": "openai",
        "api_key": "your-groq-api-key-here",
        "base_url": "https://api.groq.com/openai/v1",
        "model_name": "openai/gpt-oss-20b",
        "temperature": 0.7,
        "max_tokens": 50,
        "timeout": 1,     # Very short timeout to trigger timeout
        "max_retries": 2,
        "retry_delay": 1
    }
    
    try:
        llm = LLMProvider(config)
        
        dialogue = [
            {"role": "user", "content": "Tell me a short story"}
        ]
        
        print("üì§ Sending request with 1s timeout (may trigger timeout retry)...")
        
        start_time = time.time()
        
        response_text = ""
        for chunk in llm.response("test_session", dialogue):
            response_text += chunk
            print(f"üì• {chunk}", end="", flush=True)
        
        end_time = time.time()
        
        print(f"\n‚úÖ Completed in {end_time - start_time:.2f}s")
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Expected timeout behavior: {e}")
        return True

def main():
    """Run all tests"""
    print("üöÄ TESTING GROQ LLM RETRY LOGIC")
    print("="*60)
    print("This will test:")
    print("‚úì Normal API operation")
    print("‚úì 401 error retry logic")  
    print("‚úì Timeout handling")
    print()
    
    results = []
    
    # Test 1: Normal operation
    results.append(test_successful_connection())
    
    # Test 2: Invalid API key (401 errors)
    results.append(test_invalid_api_key())
    
    # Test 3: Timeout scenario
    results.append(test_timeout_scenario())
    
    # Summary
    print("\n" + "="*60)
    print("üìä TEST SUMMARY")
    print("="*60)
    
    passed = sum(results)
    total = len(results)
    
    print(f"‚úÖ Passed: {passed}/{total}")
    
    if passed == total:
        print("üéâ All tests passed! Retry logic is working correctly.")
        print("\nüîß Configuration recommendations:")
        print("   ‚Ä¢ timeout: 15s (good for Groq)")
        print("   ‚Ä¢ max_retries: 2 (retry once)")
        print("   ‚Ä¢ retry_delay: 1s (quick retry)")
    else:
        print("‚ö†Ô∏è  Some tests failed. Check the logs above.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)