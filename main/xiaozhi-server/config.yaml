server:
  # Server listening address and port
  ip: 0.0.0.0
  port: 8000
  http_port: 8003
  websocket: ws://192.168.1.118:8000/xiaozhi/v1/
  vision_explain: http://your-ip-or-domain:port/mcp/vision/explain
  timezone_offset: +8
  # MQTT Gateway configuration for OTA response
  mqtt_gateway:
    enabled: true
    broker: 192.168.1.118
    port: 1883
    udp_port: 8884
  auth:
    enabled: false
    tokens:
      - token: "your-token1" # Device 1 token
        name: "your-device-name1" # Device 1 identifier
      - token: "your-token2" # Device 2 token
        name: "your-device-name2" # Device 2 identifier

prompt: |
  PERSONA: You are Cheeko, a friendly, curious, and playful AI friend for children aged 4+. 
  You talk in short, clear, and fun sentences. 
  You always:
  1. Start with a cheerful greeting if it’s the first message in the conversation.
  2. Answer in a simple and imaginative way, using age-appropriate words.
  3. Praise or encourage the child after they respond.
  4. End every single message with a fun or curious follow-up question related to the topic OR a playful new topic if the child seems stuck.
  5. Use a warm and positive tone at all times.
  6. Avoid scary, negative, or boring content.
  7. If telling a story, pause sometimes to ask the child to imagine what happens next.
  8. Never say “I don’t know” — instead, make a guess or turn it into a playful thought.
  9. Keep the conversation safe and friendly.
  Your main goal is to keep the child talking and smiling.
# Response length constraint
response_constraints:
  max_words: 50
  enforce_limit: true

# Exit commands configuration
exit_commands:
  - "exit"
  - "quit"
  - "bye"
  - "goodbye"

# Xiaozhi welcome message configuration
xiaozhi:
  type: "hello"
  greeting: "Hello! I'm Cheeko, your friendly AI companion!"
  version: 3

# Wakeup words configuration
enable_wakeup_words_response_cache: false
require_wake_word: true  # Require wake word before processing commands
wake_word_timeout: 30  # Seconds to wait after wake word before requiring it again
wakeup_words:
  - "hey cheeko"
  - "hi cheeko"  
  - "hello cheeko"
  - "cheeko"
  - "okay cheeko"
wakeup_words_response: "Yes! I'm here! What would you like to talk about?"
min_audio_duration_ms: 500  # Minimum audio duration to process (filters out short noises)

selected_module:
  LLM: openai
  TTS: elevenlabs
  VAD: SileroVAD
  Memory: mem_local_short
  TTS: elevenlabs
  ASR: SherpaZipformerGigaspeechEN
  Intent: function_call

LLM:
  openai:
    # Groq API for fast Llama inference (OpenAI-compatible)
    type: openai
    # Get your API key from https://console.groq.com/keys
    api_key: "YOUR_GROQ_API_KEY" # ← ADD YOUR GROQ API KEY HERE
    # Available models: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
    model_name: llama-3.3-70b-versatile
    base_url: https://api.groq.com/openai/v1
    temperature: 0.7
    max_tokens: 100
    top_p: 1.0
    frequency_penalty: 0
  # ChatGLMLLM:
  #   api_key: d970a2e5c3f84c8eb868bfa90d81c602.Kh60ADq0Vzf8kmSw
  #   max_tokens: 100
  #   temperature: 0.7
VAD:
  SileroVAD:
    type: silero
    threshold: 0.5
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 1000
  TenVAD_ONNX:
    frame_size: 512
    frame_window_threshold: 6
    hop_size: 256
    min_silence_duration_ms: 1000
    model_path: models/ten-vad-onnx
    sample_rate: 16000
    threshold: 0.6
    threshold_low: 0.2
    type: ten_vad_onnx

ASR:
  SherpaASR:
    type: sherpa_onnx_local
    model_dir: models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17
    output_dir: tmp/
    # Force English language recognition
    language: "en"
    # Prefer English over other languages
    language_priority: ["en", "en-US"]


  SherpaWhisperBaseEN:
    model_dir: models/sherpa-onnx-whisper-base.en
    model_type: whisper
    output_dir: tmp/
    type: sherpa_onnx_local
  SherpaWhisperSmallEN:
    model_dir: models/sherpa-onnx-whisper-small.en
    model_type: whisper
    output_dir: tmp/
    type: sherpa_onnx_local
  SherpaWhisperTinyEN:
    model_dir: models/sherpa-onnx-whisper-tiny.en
    model_type: whisper
    output_dir: tmp/
    type: sherpa_onnx_local
  SherpaZipformerEN:
    model_dir: models/sherpa-onnx-zipformer-en-2023-04-01
    model_type: zipformer
    output_dir: tmp/
    type: sherpa_onnx_local
  SherpaZipformerGigaspeechEN:
    model_dir: models/sherpa-onnx-zipformer-gigaspeech-2023-12-12
    model_type: zipformer
    output_dir: tmp/
    type: sherpa_onnx_local

  # groq_whisper:
  #   # api_key: your_groq_api_key_here
  #   # model: whisper-large-v3
  #   # language: zh
  #   # temperature: 0.0
  #   # response_format: text
  #   # output_dir: tmp/
  #   # Groq's Whisper API for speech-to-text
  #   # Get your API key from: https://console.groq.com/keys
  #   type: openai
  #   api_key: ${GROQ_API_KEY}
  #   # Available models: whisper-large-v3, whisper-large-v3-turbo
  #   model: whisper-large-v3
  #   # Language code (e.g., zh for Chinese, en for English, auto for automatic detection)
  #   language: en
  #   # Temperature for sampling (0.0 for deterministic, higher for more variation)
  #   temperature: 0.0
  #   # Response format: text, json, verbose_json, srt, vtt
  #   response_format: text
  #   # Base URL (optional, defaults to Groq's API)
  #   base_url: https://api.groq.com
  #   # Timeout in seconds
  #   timeout: 60
  #   output_dir: tmp/
TTS:
  elevenlabs:
    api_key: sk_52c940fe01587efe7247074e1229bef0d81d32194ab3bb42 # ← ADD YOUR ELEVENLABS API KEY HERE
    # Voice ID - default is Rachel, you can find more voices at https://elevenlabs.io/voice-library
    voice_id: vGQNBgLaiM3EdZtxIiuY
    # Model ID - eleven_multilingual_v2 supports multiple languages
    model_id: eleven_turbo_v2_5
    # Voice settings (0.0 to 1.0)
    stability: 0.75
    similarity_boost: 0.75
    style: 0.0
    use_speaker_boost: true
    # Speech speed control (0.25 to 4.0, default is 1.0)
    # Lower values = slower speech, higher values = faster speech
    speaking_rate: 0. 2 # 20% slower than normal
    # Output format: mp3_44100_128, mp3_22050_32, pcm_16000, pcm_22050, pcm_24000, pcm_44100
    output_format: mp3_44100_128
    # Streaming optimization (0-4, higher = lower latency but potentially lower quality)
    optimize_streaming_latency: 0
    output_dir: tmp/
  kittentts:
    format: wav
    model_name: KittenML/kitten-tts-nano-0.1
    output_dir: tmp/
    sample_rate: 16000
    speed: 0.9
    voice: expr-voice-5-f
  siliconflow:
    access_token: sk-kuyamprtzyvtetbnsyoysbbxuwqzyraldecobjetvdeowzte
    fallback:
      elevenlabs:
        api_key: sk_52c940fe01587efe7247074e1229bef0d81d32194ab3bb42
        model_id: eleven_turbo_v2_5
        optimize_streaming_latency: 0
        output_dir: tmp/
        output_format: mp3_44100_128
        similarity_boost: 0.75
        stability: 0.75
        style: 0.0
        use_speaker_boost: true
        voice_id: XJ2fW4ybq7HouelYYGcL
      enabled: true
    gain: 0
    model: FunAudioLLM/CosyVoice2-0.5B
    output_dir: tmp/
    response_format: mp3
    speed: 1.0
    voice: diana

log:
  log_level: DEBUG

# Enable reading configuration from manager API (Java backend)
read_config_from_api: false  # Set to true when Java API is running

# Chat history and reporting configuration
chat_history_conf: 2  # 0=disabled, 1=text only, 2=text+audio
report_tts_enable: true  # Enable TTS reporting to database

# Manager API configuration for MySQL database integration
manager-api:
  # URL of your Java backend server
  # Replace with your actual backend URL if different
  url: "http://localhost:8002"
  # Secret key for authentication - this will be auto-generated when you first run the Java backend
  # You can find it in the sys_params table with param_code = 'server.secret'
  secret: "cheeko-secret-key-2025"
  # Timeout in seconds for API requests
  timeout: 30
  # Maximum retry count for failed requests
  max_retries: 3
  # Initial retry delay in seconds
  retry_delay: 5

# Weather plugin configuration
plugins:
  get_weather:
    api_key: "12dd0eea5789636262549c9ec7f4f7d8" # Your OpenWeatherMap API key
    default_location: "Bangalore" # Default Indian city
    units: "metric" # Celsius temperature
    lang: "en" # Language for weather descriptions

  # Indian news API configuration (recommended for Indian users)
  get_indian_news_api:
    default_category: "general"
    categories:
      - "general"
      - "business"
      - "technology"
      - "science"
      - "education"
    lang: "en_US"
    # Optional: Add your free API keys for better news coverage
    # newsapi_key: "your_newsapi_key_here"  # Get from https://newsapi.org/
    # gnews_key: "your_gnews_key_here"      # Get from https://gnews.io/

  # Keep international news for comparison
  get_news_from_newsnow:
    url: "https://newsnow.busiyi.world/api/s?id="
    news_sources: "Wall Street Journal;Hacker News;BBC News" # International sources

# Intent recognition configuration
Intent:
  function_call:
    type: function_call
    functions:
      - play_music
      - get_weather # Weather function
      - get_indian_news_api # Indian news function (recommended)
      - get_news_from_newsnow # International news (English only)
      # Disabled Chinese news to prevent Chinese responses:
      # - get_news_from_chinanews

# Memory configuration for conversation history
Memory:
  mem_local_short:
    type: mem_local_short
    max_history: 10  # Number of conversation turns to remember
    llm: openai  # Use the same LLM for memory processing
    enable_summary: true  # Enable conversation summarization
    summary_interval: 5  # Summarize every 5 turns
