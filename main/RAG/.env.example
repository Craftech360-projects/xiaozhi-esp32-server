# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# LLM Configuration (choose one)
# Option 1: OpenAI (for OpenAI embeddings and GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Option 2: Groq (for fast inference with various models)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# LLM Provider Selection
LLM_PROVIDER=groq  # Options: openai, groq, none

# AWS Configuration (optional, for S3 data loading)
AWS_ACCESS_KEY_ID=your_aws_access_key_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_key_here
AWS_REGION=us-east-1

# Collection Configuration
COLLECTION_NAME=rag_collection
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200